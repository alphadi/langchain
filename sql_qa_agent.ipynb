{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5baddfbe-2a6f-445e-bd64-7391eec3a9d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --upgrade --quiet langchain-community langchainhub langgraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306a1d27-8421-4527-b102-7d4b09b8f18a",
   "metadata": {},
   "source": [
    "At a high-level, the steps of these systems are:\n",
    "\n",
    "Convert question to SQL query: Model converts user input to a SQL query.\n",
    "Execute SQL query: Execute the query.\n",
    "Answer the question: Model responds to user input using the query results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b6aaa23-9451-4c89-b587-bd58bef60087",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter API key for OpenAI:  ········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e400d4b-daa3-4f42-9d16-45a55a0095da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/AV/Documents/Dev/Langchain/Greg Kamradt Tutorials/chinook-database/ChinookDatabase/DataSources\n"
     ]
    }
   ],
   "source": [
    "cd /Users/AV/Documents/Dev/Langchain/Greg Kamradt Tutorials/chinook-database/ChinookDatabase/DataSources\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bbc7005-1a54-4b1e-b9e1-57c71e576a84",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sqlite\n",
      "['Album', 'Artist', 'Customer', 'Employee', 'Genre', 'Invoice', 'InvoiceLine', 'MediaType', 'Playlist', 'PlaylistTrack', 'Track']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"[(1, 'AC/DC'), (2, 'Accept'), (3, 'Aerosmith'), (4, 'Alanis Morissette'), (5, 'Alice In Chains'), (6, 'Antônio Carlos Jobim'), (7, 'Apocalyptica'), (8, 'Audioslave'), (9, 'BackBeat'), (10, 'Billy Cobham')]\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "\n",
    "\n",
    "\n",
    "db = SQLDatabase.from_uri(\"sqlite:///Chinook.db\")\n",
    "print(db.dialect)\n",
    "print(db.get_usable_table_names())\n",
    "db.run(\"SELECT * FROM Artist LIMIT 10;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7c4c2ce-5038-466b-a1bc-fcb84c8de5c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sqlite\n",
      "['Album', 'Artist', 'Customer', 'Employee', 'Genre', 'Invoice', 'InvoiceLine', 'MediaType', 'Playlist', 'PlaylistTrack', 'Track']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"[(1, 'AC/DC'), (2, 'Accept'), (3, 'Aerosmith'), (4, 'Alanis Morissette'), (5, 'Alice In Chains'), (6, 'Antônio Carlos Jobim'), (7, 'Apocalyptica'), (8, 'Audioslave'), (9, 'BackBeat'), (10, 'Billy Cobham')]\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "\n",
    "\n",
    "\n",
    "db = SQLDatabase.from_uri(\"sqlite:///Chinook.db\")\n",
    "print(db.dialect)\n",
    "print(db.get_usable_table_names())\n",
    "db.run(\"SELECT * FROM Artist LIMIT 10;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c9551e-5af7-49c8-9c84-7b217480e813",
   "metadata": {},
   "source": [
    "## Chains\n",
    "Chains are compositions of predictable steps. In LangGraph, we can represent a chain via simple sequence of nodes. Let's create a sequence of steps that, given a question, does the following:\n",
    "\n",
    "1) converts the question into a SQL query;\n",
    "2) executes the query;\n",
    "3) uses the result to answer the original question.\n",
    "\n",
    "There are scenarios not supported by this arrangement. For example, this system will execute a SQL query for any user input-- even \"hello\". Importantly, as we'll see below, some questions require more than one query to answer. We will address these scenarios in the Agents section.\n",
    "\n",
    "Application state\n",
    "The LangGraph state of our application controls what data is input to the application, transferred between steps, and output by the application. It is typically a TypedDict, but can also be a Pydantic BaseModel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc1d1881-5f7b-4f54-a90d-f4748f4a7762",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    query: str\n",
    "    result: str\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ab64d2e-1754-44e8-ab6a-1e61598e127f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/AV/anaconda3/lib/python3.11/site-packages/langsmith/client.py:256: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "Given an input question, create a syntactically correct \u001b[33;1m\u001b[1;3m{dialect}\u001b[0m query to run to help find the answer. Unless the user specifies in his question a specific number of examples they wish to obtain, always limit your query to at most \u001b[33;1m\u001b[1;3m{top_k}\u001b[0m results. You can order the results by a relevant column to return the most interesting examples in the database.\n",
      "\n",
      "Never query for all the columns from a specific table, only ask for a the few relevant columns given the question.\n",
      "\n",
      "Pay attention to use only the column names that you can see in the schema description. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table.\n",
      "\n",
      "Only use the following tables:\n",
      "\u001b[33;1m\u001b[1;3m{table_info}\u001b[0m\n",
      "\n",
      "Question: \u001b[33;1m\u001b[1;3m{input}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "\n",
    "query_prompt_template = hub.pull(\"langchain-ai/sql-query-system-prompt\")\n",
    "\n",
    "assert len(query_prompt_template.messages) == 1\n",
    "query_prompt_template.messages[0].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81e13908-bfd5-4f54-a2c2-76f17f1a3a83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing_extensions import Annotated\n",
    "\n",
    "\n",
    "class QueryOutput(TypedDict):\n",
    "    \"\"\"Generated SQL query.\"\"\"\n",
    "\n",
    "    query: Annotated[str, ..., \"Syntactically valid SQL query.\"]\n",
    "\n",
    "\n",
    "def write_query(state: State):\n",
    "    \"\"\"Generate SQL query to fetch information.\"\"\"\n",
    "    prompt = query_prompt_template.invoke(\n",
    "        {\n",
    "            \"dialect\": db.dialect,\n",
    "            \"top_k\": 10,\n",
    "            \"table_info\": db.get_table_info(),\n",
    "            \"input\": state[\"question\"],\n",
    "        }\n",
    "    )\n",
    "    structured_llm = llm.with_structured_output(QueryOutput)\n",
    "    result = structured_llm.invoke(prompt)\n",
    "    return {\"query\": result[\"query\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed2ef29d-deb7-4e26-b4e3-c0b1b595c538",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'SELECT COUNT(*) AS EmployeeCount FROM Employee;'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "write_query({\"question\": \"How many Employees are there?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c356bf84-454f-428d-ba5c-3c63fdb37bc6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'SELECT * FROM Album LIMIT 10;'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "write_query({\"question\": \"How many stars are in our universe?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48c8ec0-cbf7-4933-ae64-ddfbb46a66c2",
   "metadata": {},
   "source": [
    "## Execute query\n",
    "\n",
    "This is the most dangerous part of creating a SQL chain. Consider carefully if it is OK to run automated queries over your data. Minimize the database connection permissions as much as possible. Consider adding a human approval step to you chains before query execution (see below).\n",
    "\n",
    "To execute the query, we will load a tool from langchain-community. Our execute_query node will just wrap this tool:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "377bd00d-5709-4bcc-b827-73fe3912f970",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_community.tools.sql_database.tool import QuerySQLDatabaseTool\n",
    "\n",
    "\n",
    "def execute_query(state: State):\n",
    "    \"\"\"Execute SQL query.\"\"\"\n",
    "    execute_query_tool = QuerySQLDatabaseTool(db=db)\n",
    "    return {\"result\": execute_query_tool.invoke(state[\"query\"])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e31003e-5186-48f2-b711-87b82de573a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'result': '[(8,)]'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execute_query({\"query\": \"SELECT COUNT(EmployeeId) AS EmployeeCount FROM Employee;\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47f846a-33cb-4567-aa4f-d1b554b46a09",
   "metadata": {},
   "source": [
    "## Generate answer\n",
    "Finally, our last step generates an answer to the question \n",
    "given the information pulled from the database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c0459a11-3e8c-4e64-9933-84a14778ef48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_answer(state: State):\n",
    "    \"\"\"Answer question using retrieved information as context.\"\"\"\n",
    "    prompt = (\n",
    "        \"Given the following user question, corresponding SQL query, \"\n",
    "        \"and SQL result, answer the user question.\\n\\n\"\n",
    "        f'Question: {state[\"question\"]}\\n'\n",
    "        f'SQL Query: {state[\"query\"]}\\n'\n",
    "        f'SQL Result: {state[\"result\"]}'\n",
    "    )\n",
    "    response = llm.invoke(prompt)\n",
    "    return {\"answer\": response.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ce872e-f1bd-4e48-9f45-a4710f7e1acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "896eca62-e1db-4ce1-816b-26810d64c963",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langgraph.graph import START, StateGraph\n",
    "\n",
    "graph_builder = StateGraph(State).add_sequence(\n",
    "    [write_query, execute_query, generate_answer]\n",
    ")\n",
    "graph_builder.add_edge(START, \"write_query\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bf264d31-d1e5-4ac4-9776-f7b785f9bda2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "94014e99-92f4-4503-9e80-21cf2b8533cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'write_query': {'query': 'SELECT COUNT(*) AS EmployeeCount FROM Employee;'}}\n",
      "{'execute_query': {'result': '[(8,)]'}}\n",
      "{'generate_answer': {'answer': 'There are 8 employees.'}}\n"
     ]
    }
   ],
   "source": [
    "for step in graph.stream(\n",
    "    {\"question\": \"How many employees are there?\"}, stream_mode=\"updates\"\n",
    "):\n",
    "    print(step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782a6a7d-e54f-46c7-9a0f-682d4ae4feb5",
   "metadata": {},
   "source": [
    "## Human-in-the-loop\n",
    "LangGraph supports a number of features that can be useful for this workflow. One of them is human-in-the-loop: we can interrupt our application before sensitive steps (such as the execution of a SQL query) for human review. This is enabled by LangGraph's persistence layer, which saves run progress to your storage of choice. Below, we specify storage in-memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "02da2b95-4594-4b51-989f-16804e560b23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver()\n",
    "graph = graph_builder.compile(checkpointer=memory, interrupt_before=[\"execute_query\"])\n",
    "\n",
    "# Now that we're using persistence, we need to specify a thread ID\n",
    "# so that we can continue the run after review.\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7a49504b-a7ca-486c-b813-aa92d1a1d38e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'write_query': {'query': 'SELECT COUNT(*) as EmployeeCount FROM Employee;'}}\n",
      "{'__interrupt__': ()}\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want to go to execute query? (yes/no):  no\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operation cancelled by user.\n"
     ]
    }
   ],
   "source": [
    "for step in graph.stream(\n",
    "    {\"question\": \"How many employees are there?\"},\n",
    "    config,\n",
    "    stream_mode=\"updates\",\n",
    "):\n",
    "    print(step)\n",
    "\n",
    "try:\n",
    "    user_approval = input(\"Do you want to go to execute query? (yes/no): \")\n",
    "except Exception:\n",
    "    user_approval = \"no\"\n",
    "\n",
    "if user_approval.lower() == \"yes\":\n",
    "    # If approved, continue the graph execution\n",
    "    for step in graph.stream(None, config, stream_mode=\"updates\"):\n",
    "        print(step)\n",
    "else:\n",
    "    print(\"Operation cancelled by user.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1eb6eb8d-77c3-41a2-b7da-bb1c505db578",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[QuerySQLDatabaseTool(description=\"Input to this tool is a detailed and correct SQL query, output is a result from the database. If the query is not correct, an error message will be returned. If an error is returned, rewrite the query, check the query, and try again. If you encounter an issue with Unknown column 'xxxx' in 'field list', use sql_db_schema to query the correct table fields.\", db=<langchain_community.utilities.sql_database.SQLDatabase object at 0x1282564d0>),\n",
       " InfoSQLDatabaseTool(description='Input to this tool is a comma-separated list of tables, output is the schema and sample rows for those tables. Be sure that the tables actually exist by calling sql_db_list_tables first! Example Input: table1, table2, table3', db=<langchain_community.utilities.sql_database.SQLDatabase object at 0x1282564d0>),\n",
       " ListSQLDatabaseTool(db=<langchain_community.utilities.sql_database.SQLDatabase object at 0x1282564d0>),\n",
       " QuerySQLCheckerTool(description='Use this tool to double check if your query is correct before executing it. Always use this tool before executing a query with sql_db_query!', db=<langchain_community.utilities.sql_database.SQLDatabase object at 0x1282564d0>, llm=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x11d654710>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x11dc8a610>, root_client=<openai.OpenAI object at 0x11d3f2790>, root_async_client=<openai.AsyncOpenAI object at 0x11dc2a990>, model_name='gpt-4o-mini', model_kwargs={}, openai_api_key=SecretStr('**********')), llm_chain=LLMChain(verbose=False, prompt=PromptTemplate(input_variables=['dialect', 'query'], input_types={}, partial_variables={}, template='\\n{query}\\nDouble check the {dialect} query above for common mistakes, including:\\n- Using NOT IN with NULL values\\n- Using UNION when UNION ALL should have been used\\n- Using BETWEEN for exclusive ranges\\n- Data type mismatch in predicates\\n- Properly quoting identifiers\\n- Using the correct number of arguments for functions\\n- Casting to the correct data type\\n- Using the proper columns for joins\\n\\nIf there are any of the above mistakes, rewrite the query. If there are no mistakes, just reproduce the original query.\\n\\nOutput the final SQL query only.\\n\\nSQL Query: '), llm=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x11d654710>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x11dc8a610>, root_client=<openai.OpenAI object at 0x11d3f2790>, root_async_client=<openai.AsyncOpenAI object at 0x11dc2a990>, model_name='gpt-4o-mini', model_kwargs={}, openai_api_key=SecretStr('**********')), output_parser=StrOutputParser(), llm_kwargs={}))]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.agent_toolkits import SQLDatabaseToolkit\n",
    "\n",
    "toolkit = SQLDatabaseToolkit(db=db, llm=llm)\n",
    "\n",
    "tools = toolkit.get_tools()\n",
    "\n",
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a964ed62-e166-4cda-b110-4dd38f2d16e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/AV/anaconda3/lib/python3.11/site-packages/langsmith/client.py:256: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "You are an agent designed to interact with a SQL database.\n",
      "Given an input question, create a syntactically correct \u001b[33;1m\u001b[1;3m{dialect}\u001b[0m query to run, then look at the results of the query and return the answer.\n",
      "Unless the user specifies a specific number of examples they wish to obtain, always limit your query to at most \u001b[33;1m\u001b[1;3m{top_k}\u001b[0m results.\n",
      "You can order the results by a relevant column to return the most interesting examples in the database.\n",
      "Never query for all the columns from a specific table, only ask for the relevant columns given the question.\n",
      "You have access to tools for interacting with the database.\n",
      "Only use the below tools. Only use the information returned by the below tools to construct your final answer.\n",
      "You MUST double check your query before executing it. If you get an error while executing a query, rewrite the query and try again.\n",
      "\n",
      "DO NOT make any DML statements (INSERT, UPDATE, DELETE, DROP etc.) to the database.\n",
      "\n",
      "To start you should ALWAYS look at the tables in the database to see what you can query.\n",
      "Do NOT skip this step.\n",
      "Then you should query the schema of the most relevant tables.\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "\n",
    "prompt_template = hub.pull(\"langchain-ai/sql-agent-system-prompt\")\n",
    "\n",
    "assert len(prompt_template.messages) == 1\n",
    "prompt_template.messages[0].pretty_print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "43c9f563-1139-4053-8c37-90217d3a5599",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "system_message = prompt_template.format(dialect=\"SQLite\", top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b0bfbe7c-d618-4e62-8f9d-4463e4468d85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "agent_executor = create_react_agent(llm, tools, prompt=system_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d6956598-e30c-475b-b1d7-ad6fa9c08d03",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Which country's customers spent the most?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  sql_db_list_tables (call_hZwLLpjpGSbudYAuMR2XxHmW)\n",
      " Call ID: call_hZwLLpjpGSbudYAuMR2XxHmW\n",
      "  Args:\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: sql_db_list_tables\n",
      "\n",
      "Album, Artist, Customer, Employee, Genre, Invoice, InvoiceLine, MediaType, Playlist, PlaylistTrack, Track\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  sql_db_schema (call_Cq7MFwScmSBYMc8js8WTIxVD)\n",
      " Call ID: call_Cq7MFwScmSBYMc8js8WTIxVD\n",
      "  Args:\n",
      "    table_names: Customer\n",
      "  sql_db_schema (call_kVj1MLV9NfjJciZa0HbeUTGl)\n",
      " Call ID: call_kVj1MLV9NfjJciZa0HbeUTGl\n",
      "  Args:\n",
      "    table_names: Invoice\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: sql_db_schema\n",
      "\n",
      "\n",
      "CREATE TABLE \"Invoice\" (\n",
      "\t\"InvoiceId\" INTEGER NOT NULL, \n",
      "\t\"CustomerId\" INTEGER NOT NULL, \n",
      "\t\"InvoiceDate\" DATETIME NOT NULL, \n",
      "\t\"BillingAddress\" NVARCHAR(70), \n",
      "\t\"BillingCity\" NVARCHAR(40), \n",
      "\t\"BillingState\" NVARCHAR(40), \n",
      "\t\"BillingCountry\" NVARCHAR(40), \n",
      "\t\"BillingPostalCode\" NVARCHAR(10), \n",
      "\t\"Total\" NUMERIC(10, 2) NOT NULL, \n",
      "\tPRIMARY KEY (\"InvoiceId\"), \n",
      "\tFOREIGN KEY(\"CustomerId\") REFERENCES \"Customer\" (\"CustomerId\")\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from Invoice table:\n",
      "InvoiceId\tCustomerId\tInvoiceDate\tBillingAddress\tBillingCity\tBillingState\tBillingCountry\tBillingPostalCode\tTotal\n",
      "1\t2\t2021-01-01 00:00:00\tTheodor-Heuss-Straße 34\tStuttgart\tNone\tGermany\t70174\t1.98\n",
      "2\t4\t2021-01-02 00:00:00\tUllevålsveien 14\tOslo\tNone\tNorway\t0171\t3.96\n",
      "3\t8\t2021-01-03 00:00:00\tGrétrystraat 63\tBrussels\tNone\tBelgium\t1000\t5.94\n",
      "*/\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  sql_db_query_checker (call_Sp0ITaGeVJOvUJa2IR7DnKqx)\n",
      " Call ID: call_Sp0ITaGeVJOvUJa2IR7DnKqx\n",
      "  Args:\n",
      "    query: SELECT c.Country, SUM(i.Total) AS TotalSpent\n",
      "FROM Customer c\n",
      "JOIN Invoice i ON c.CustomerId = i.CustomerId\n",
      "GROUP BY c.Country\n",
      "ORDER BY TotalSpent DESC\n",
      "LIMIT 5;\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: sql_db_query_checker\n",
      "\n",
      "```sql\n",
      "SELECT c.Country, SUM(i.Total) AS TotalSpent\n",
      "FROM Customer c\n",
      "JOIN Invoice i ON c.CustomerId = i.CustomerId\n",
      "GROUP BY c.Country\n",
      "ORDER BY TotalSpent DESC\n",
      "LIMIT 5;\n",
      "```\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  sql_db_query (call_zsfJBMQijE9vhlsZEhPkQQaJ)\n",
      " Call ID: call_zsfJBMQijE9vhlsZEhPkQQaJ\n",
      "  Args:\n",
      "    query: SELECT c.Country, SUM(i.Total) AS TotalSpent\n",
      "FROM Customer c\n",
      "JOIN Invoice i ON c.CustomerId = i.CustomerId\n",
      "GROUP BY c.Country\n",
      "ORDER BY TotalSpent DESC\n",
      "LIMIT 5;\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: sql_db_query\n",
      "\n",
      "[('USA', 523.0600000000003), ('Canada', 303.9599999999999), ('France', 195.09999999999994), ('Brazil', 190.09999999999997), ('Germany', 156.48)]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The countries whose customers spent the most are:\n",
      "\n",
      "1. **USA**: $523.06\n",
      "2. **Canada**: $303.96\n",
      "3. **France**: $195.10\n",
      "4. **Brazil**: $190.10\n",
      "5. **Germany**: $156.48\n"
     ]
    }
   ],
   "source": [
    "question = \"Which country's customers spent the most?\"\n",
    "\n",
    "for step in agent_executor.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": question}]},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c117ad2f-ad04-47bd-8915-ab1cb1d0f293",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Describe the playlisttrack table\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  sql_db_list_tables (call_eGozneVo8EsrdEt9jJNQA9Mn)\n",
      " Call ID: call_eGozneVo8EsrdEt9jJNQA9Mn\n",
      "  Args:\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: sql_db_list_tables\n",
      "\n",
      "Album, Artist, Customer, Employee, Genre, Invoice, InvoiceLine, MediaType, Playlist, PlaylistTrack, Track\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  sql_db_schema (call_fsFBapZcGtvi7gKmLjTPwjs7)\n",
      " Call ID: call_fsFBapZcGtvi7gKmLjTPwjs7\n",
      "  Args:\n",
      "    table_names: PlaylistTrack\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: sql_db_schema\n",
      "\n",
      "\n",
      "CREATE TABLE \"PlaylistTrack\" (\n",
      "\t\"PlaylistId\" INTEGER NOT NULL, \n",
      "\t\"TrackId\" INTEGER NOT NULL, \n",
      "\tPRIMARY KEY (\"PlaylistId\", \"TrackId\"), \n",
      "\tFOREIGN KEY(\"TrackId\") REFERENCES \"Track\" (\"TrackId\"), \n",
      "\tFOREIGN KEY(\"PlaylistId\") REFERENCES \"Playlist\" (\"PlaylistId\")\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from PlaylistTrack table:\n",
      "PlaylistId\tTrackId\n",
      "1\t3402\n",
      "1\t3389\n",
      "1\t3390\n",
      "*/\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The `PlaylistTrack` table has the following schema:\n",
      "\n",
      "- **Columns**:\n",
      "  - `PlaylistId`: INTEGER, **not null** (Foreign key referencing `Playlist(PlaylistId)`)\n",
      "  - `TrackId`: INTEGER, **not null** (Foreign key referencing `Track(TrackId)`)\n",
      "\n",
      "- **Primary Key**: A composite primary key consisting of both `PlaylistId` and `TrackId`.\n",
      "\n",
      "This table connects playlists and tracks, indicating which tracks belong to which playlists. \n",
      "\n",
      "**Sample Data**:\n",
      "- (1, 3402)\n",
      "- (1, 3389)\n",
      "- (1, 3390)\n"
     ]
    }
   ],
   "source": [
    "question = \"Describe the playlisttrack table\"\n",
    "\n",
    "for step in agent_executor.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": question}]},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5ce617f3-6583-4bca-865a-be1d9c579fb6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -qU langchain-chroma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "55e3ef24-3936-4d65-9025-cea6f7cf1ace",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "vector_store = Chroma(embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "99aafacd-d15c-4877-a4bd-f60ed35c3291",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Afrociberdelia',\n",
       " 'Grieg: Peer Gynt Suites & Sibelius: Pelléas et Mélisande',\n",
       " 'Maquinarama',\n",
       " 'Let There Be Rock',\n",
       " 'Volume Dois']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast\n",
    "import re\n",
    "\n",
    "\n",
    "def query_as_list(db, query):\n",
    "    res = db.run(query)\n",
    "    res = [el for sub in ast.literal_eval(res) for el in sub if el]\n",
    "    res = [re.sub(r\"\\b\\d+\\b\", \"\", string).strip() for string in res]\n",
    "    return list(set(res))\n",
    "\n",
    "\n",
    "artists = query_as_list(db, \"SELECT Name FROM Artist\")\n",
    "albums = query_as_list(db, \"SELECT Title FROM Album\")\n",
    "albums[:5]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "076a57f6-38da-45b1-a8e5-3a003877d111",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "PermissionDeniedError",
     "evalue": "Error code: 403 - {'error': {'message': 'Project `proj_ukryVWbqo42JlMofydmcJxzy` does not have access to model `text-embedding-3-large`', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionDeniedError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magent_toolkits\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_retriever_tool\n\u001b[0;32m----> 3\u001b[0m _ \u001b[38;5;241m=\u001b[39m vector_store\u001b[38;5;241m.\u001b[39madd_texts(artists \u001b[38;5;241m+\u001b[39m albums)\n\u001b[1;32m      4\u001b[0m retriever \u001b[38;5;241m=\u001b[39m vector_store\u001b[38;5;241m.\u001b[39mas_retriever(search_kwargs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mk\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m5\u001b[39m})\n\u001b[1;32m      5\u001b[0m description \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse to look up values to filter on. Input is an approximate spelling \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof the proper noun, output is valid proper nouns. Use the noun most \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimilar to the search.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      9\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain_chroma/vectorstores.py:532\u001b[0m, in \u001b[0;36mChroma.add_texts\u001b[0;34m(self, texts, metadatas, ids, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m texts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(texts)\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embedding_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 532\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embedding_function\u001b[38;5;241m.\u001b[39membed_documents(texts)\n\u001b[1;32m    533\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m metadatas:\n\u001b[1;32m    534\u001b[0m     \u001b[38;5;66;03m# fill metadatas with empty dicts if somebody\u001b[39;00m\n\u001b[1;32m    535\u001b[0m     \u001b[38;5;66;03m# did not specify metadata for all texts\u001b[39;00m\n\u001b[1;32m    536\u001b[0m     length_diff \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(texts) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(metadatas)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain_openai/embeddings/base.py:588\u001b[0m, in \u001b[0;36mOpenAIEmbeddings.embed_documents\u001b[0;34m(self, texts, chunk_size)\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[38;5;66;03m# NOTE: to keep things simple, we assume the list may contain texts longer\u001b[39;00m\n\u001b[1;32m    586\u001b[0m \u001b[38;5;66;03m#       than the maximum context and use length-safe embedding function.\u001b[39;00m\n\u001b[1;32m    587\u001b[0m engine \u001b[38;5;241m=\u001b[39m cast(\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeployment)\n\u001b[0;32m--> 588\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_len_safe_embeddings(texts, engine\u001b[38;5;241m=\u001b[39mengine)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain_openai/embeddings/base.py:483\u001b[0m, in \u001b[0;36mOpenAIEmbeddings._get_len_safe_embeddings\u001b[0;34m(self, texts, engine, chunk_size)\u001b[0m\n\u001b[1;32m    481\u001b[0m batched_embeddings: List[List[\u001b[38;5;28mfloat\u001b[39m]] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m _iter:\n\u001b[0;32m--> 483\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m    484\u001b[0m         \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mtokens[i : i \u001b[38;5;241m+\u001b[39m _chunk_size], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_invocation_params\n\u001b[1;32m    485\u001b[0m     )\n\u001b[1;32m    486\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    487\u001b[0m         response \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mmodel_dump()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/openai/resources/embeddings.py:125\u001b[0m, in \u001b[0;36mEmbeddings.create\u001b[0;34m(self, input, model, dimensions, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    119\u001b[0m         embedding\u001b[38;5;241m.\u001b[39membedding \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfrombuffer(  \u001b[38;5;66;03m# type: ignore[no-untyped-call]\u001b[39;00m\n\u001b[1;32m    120\u001b[0m             base64\u001b[38;5;241m.\u001b[39mb64decode(data), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    121\u001b[0m         )\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[0;32m--> 125\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post(\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    127\u001b[0m     body\u001b[38;5;241m=\u001b[39mmaybe_transform(params, embedding_create_params\u001b[38;5;241m.\u001b[39mEmbeddingCreateParams),\n\u001b[1;32m    128\u001b[0m     options\u001b[38;5;241m=\u001b[39mmake_request_options(\n\u001b[1;32m    129\u001b[0m         extra_headers\u001b[38;5;241m=\u001b[39mextra_headers,\n\u001b[1;32m    130\u001b[0m         extra_query\u001b[38;5;241m=\u001b[39mextra_query,\n\u001b[1;32m    131\u001b[0m         extra_body\u001b[38;5;241m=\u001b[39mextra_body,\n\u001b[1;32m    132\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[1;32m    133\u001b[0m         post_parser\u001b[38;5;241m=\u001b[39mparser,\n\u001b[1;32m    134\u001b[0m     ),\n\u001b[1;32m    135\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mCreateEmbeddingResponse,\n\u001b[1;32m    136\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/openai/_base_client.py:1283\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1270\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1271\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1278\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1279\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1280\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1281\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1282\u001b[0m     )\n\u001b[0;32m-> 1283\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(cast_to, opts, stream\u001b[38;5;241m=\u001b[39mstream, stream_cls\u001b[38;5;241m=\u001b[39mstream_cls))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/openai/_base_client.py:960\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    957\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    958\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 960\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[1;32m    961\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m    962\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m    963\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[1;32m    964\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m    965\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[1;32m    966\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/openai/_base_client.py:1064\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1061\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1063\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1064\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1066\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m   1067\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1068\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1072\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[1;32m   1073\u001b[0m )\n",
      "\u001b[0;31mPermissionDeniedError\u001b[0m: Error code: 403 - {'error': {'message': 'Project `proj_ukryVWbqo42JlMofydmcJxzy` does not have access to model `text-embedding-3-large`', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}"
     ]
    }
   ],
   "source": [
    "from langchain.agents.agent_toolkits import create_retriever_tool\n",
    "\n",
    "_ = vector_store.add_texts(artists + albums)\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 5})\n",
    "description = (\n",
    "    \"Use to look up values to filter on. Input is an approximate spelling \"\n",
    "    \"of the proper noun, output is valid proper nouns. Use the noun most \"\n",
    "    \"similar to the search.\"\n",
    ")\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    name=\"search_proper_nouns\",\n",
    "    description=description,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9198f5cf-f5d1-451d-92d7-1a8e88db0d29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
